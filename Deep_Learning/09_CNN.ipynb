{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPATyPIel8LMRTqPLWdTz7X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2018007956/HYU/blob/main/Deep_Learning/09_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. MNIST dataset"
      ],
      "metadata": {
        "id": "5ZPZ1YifURYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "rVXK2mOvRnt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root='MNIST_data/',\n",
        "                                             train=True,\n",
        "                                             transform=transforms.ToTensor(),\n",
        "                                             download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='MNIST_data/',\n",
        "                                             train=False,\n",
        "                                             transform=transforms.ToTensor(),\n",
        "                                             download=True)\n",
        "\n",
        "batch_size = 128\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "xxElrGqVRnwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, 1, 1) #input channel, output channel, kernel size, stride, padding\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
        "    self.fc1 = nn.Linear(64*7*7, 128)\n",
        "    self.fc2 = nn.Linear(128, 10)\n",
        "    self.activation = nn.ReLU()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.pool(self.activation(self.conv1(x)))\n",
        "    x = self.pool(self.activation(self.conv2(x)))\n",
        "    x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "    x = self.activation(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "0DRp7l7ARnyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=CNN().to(device)"
      ],
      "metadata": {
        "id": "HsQbtAHVRn03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "WQtsdV09Rn22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "bBLZLTXZTghb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  avg_cost = 0\n",
        "  total_batch_num = len(train_dataloader)\n",
        "\n",
        "  for b_x, b_y in train_dataloader:\n",
        "    logits = model(b_x.to(device)) # forward propagation\n",
        "    loss = criterion(logits, b_y.to(device)) # get cost\n",
        "\n",
        "    avg_cost += loss/total_batch_num\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() # backward propagation\n",
        "    optimizer.step() # update parameters\n",
        "  print('Epoch : {} / {}, cost: {}'.format(epoch+1, epochs, avg_cost))"
      ],
      "metadata": {
        "id": "FccFlG2kTgjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "model.eval()\n",
        "for b_x, b_y in test_dataloader:\n",
        "  with torch.no_grad():\n",
        "    logits = model(b_x.to(device))\n",
        "\n",
        "  probs = nn.Softmax(dim=1)(logits)\n",
        "  predicts = torch.argmax(logits, dim=1)\n",
        "\n",
        "  total += len(b_y)\n",
        "  correct += (predicts == b_y.to(device)).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on test images: {100*correct//total} %')"
      ],
      "metadata": {
        "id": "7Z2UVzFpTglu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. CIFAR-10 dataset"
      ],
      "metadata": {
        "id": "OL8l_x5iUVa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "V51imri-TgoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root='CIFAR10/',\n",
        "                                             train=True,\n",
        "                                             transform=transforms.ToTensor(),\n",
        "                                             download=True)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='CIFAR10/',\n",
        "                                             train=False,\n",
        "                                             transform=transforms.ToTensor(),\n",
        "                                             download=True)\n",
        "\n",
        "batch_size = 128\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "quZWRafETgqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5) # input channel, output channel, filter size\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16*5*5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "    self.activation = nn.ReLU()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.pool(self.activation(self.conv1(x)))\n",
        "    x = self.pool(self.activation(self.conv2(x)))\n",
        "    x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "    x = self.activation(self.fc1(x))\n",
        "    x = self.activation(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "9OG16QfiUgB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=CNN().to(device)"
      ],
      "metadata": {
        "id": "gVwO8xCoUgEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "d0bfIarqUgG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "2-yPlDKEVF7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  avg_cost = 0\n",
        "  total_batch_num = len(train_dataloader)\n",
        "\n",
        "  for b_x, b_y in train_dataloader:\n",
        "    logits = model(b_x.to(device)) # forward propagation\n",
        "    loss = criterion(logits, b_y.to(device)) # get cost\n",
        "\n",
        "    avg_cost += loss/total_batch_num\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() # backward propagation\n",
        "    optimizer.step() # update parameters\n",
        "  print('Epoch : {} / {}, cost: {}'.format(epoch+1, epochs, avg_cost))"
      ],
      "metadata": {
        "id": "84AeswZPVF9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "model.eval()\n",
        "for b_x, b_y in test_dataloader:\n",
        "  with torch.no_grad():\n",
        "    logits = model(b_x.to(device))\n",
        "\n",
        "  probs = nn.Softmax(dim=1)(logits)\n",
        "  predicts = torch.argmax(logits, dim=1)\n",
        "\n",
        "  total += len(b_y)\n",
        "  correct += (predicts == b_y.to(device)).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on test images: {100*correct//total} %')"
      ],
      "metadata": {
        "id": "xQ1KRNNIVGAK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}