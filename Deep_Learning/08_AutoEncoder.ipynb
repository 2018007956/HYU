{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMS7k+O9vy+geq12mHbjH/e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2018007956/HYU/blob/main/Deep_Learning/08_AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. AutoEncoder\n",
        "2. Denoising AutoEncoder \n",
        "3. Stacked AutoEncoder  \n",
        "데이터 전처리  \n",
        "모델 및 optimizer 정의  \n",
        "학습  \n",
        "학습 결과 확인"
      ],
      "metadata": {
        "id": "Usbcv4lBSerU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "eRQ99_m9Se6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root='CIFAR10/',\n",
        "                                             train=True,\n",
        "                                             transform=transforms.ToTensor(),\n",
        "                                             download=True)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='CIFAR10/',\n",
        "                                             train=False,\n",
        "                                             transform=transforms.ToTensor(),\n",
        "                                             download=True)\n",
        "\n",
        "batch_size = 128\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "3V6HtMRkSe9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 다양한 Encoder, Decoder 학습 방법"
      ],
      "metadata": {
        "id": "rWZS-fmwy4z7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1. Encoder, Decoder class 각각 나눠서 생성 후 하나의 모델로 만들기"
      ],
      "metadata": {
        "id": "xKvqgBru6YUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.linear = nn.Linear(784, 256)\n",
        "    self.activation = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear(x)\n",
        "    x = self.activation(x)\n",
        "    return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.linear = nn.Linear(256, 784)\n",
        "    self.activation = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear(x)\n",
        "    x = self.activation(x)\n",
        "    return x\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(AutoEncoder, self).__init__()\n",
        "    self.encoder = Encoder()\n",
        "    self.decoder = Decoder()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    z = self.encoder(x)\n",
        "    x_hat = self.decoder(z)\n",
        "    return z, x_hat"
      ],
      "metadata": {
        "id": "LvDsiIxCSfAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. nn.Sequential을 사용해 한 모델에서 autoencoder 작성하기"
      ],
      "metadata": {
        "id": "XnHd9senzCOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(AutoEncoder, self).__init__()\n",
        "    self.encoder = nn.Sequential(nn.Linear(784,256),\n",
        "                                 nn.Sigmoid())\n",
        "    self.decoder = nn.Sequential(nn.Linear(256,784),\n",
        "                                 nn.Sigmoid())\n",
        "    \n",
        "  def forward(self, x):\n",
        "    z = self.encoder(x)\n",
        "    x_hat = self.decoder(z)\n",
        "    return z, x_hat"
      ],
      "metadata": {
        "id": "JeJHcd1U3Hro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Encoder, Decoder class 각각 나눠서 하나씩 부르기"
      ],
      "metadata": {
        "id": "qI11_eMFzCZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.linear = nn.Linear(784, 256)\n",
        "    self.activation = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear(x)\n",
        "    x = self.activation(x)\n",
        "    return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.linear = nn.Linear(256, 784)\n",
        "    self.activation = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear(x)\n",
        "    x = self.activation(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "H6yHFbTuSfCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder().to(device)\n",
        "decoder = Decoder().to(device)"
      ],
      "metadata": {
        "id": "csl0Lw2HSfE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 가지 방법\n",
        "# 1) Parameter List\n",
        "# params = list(encoder.parameters()) + list(decoder.parameters())\n",
        "# optimizer = optim.Adam(params, lr=0.001)\n",
        "\n",
        "# 2) 두 개의 optimizer\n",
        "optimizer = optim.Adam(\n",
        "    [\n",
        "        {\"params\": encoder.parameters(), \"lr\": 0.001},\n",
        "        {\"params\": decoder.parameters(), \"lr\": 0.001},\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "KUGUsc--3u8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_x = b_x.view(-1, 784).to(device)\n",
        "z = encoder(b_x) # forward propagation\n",
        "b_x_hat = decoder(z) # forward propagation\n",
        "loss = criterion(b_x_hat, b_x) # get cost\n",
        "\n",
        "avg_cost += loss / total_batch_num\n",
        "\n",
        "optimizer.zero_grad()\n",
        "\n",
        "loss.backward() # backward propagation\n",
        "\n",
        "optimizer.step() # update parameters"
      ],
      "metadata": {
        "id": "NNAMwf3X3u-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습"
      ],
      "metadata": {
        "id": "5Vzd0RYR5dNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoEncoder().to(device)"
      ],
      "metadata": {
        "id": "emUV0G110CVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "s2uBrFTS0CZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "G9SnnFZB0CcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = test_dataset[1051][0].view(-1, 784).to(device)"
      ],
      "metadata": {
        "id": "S8EvJR_60CfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  avg_cost = 0\n",
        "  total_batch_num = len(train_dataloader)\n",
        "\n",
        "  for b_x, b_y in train_dataloader:\n",
        "    b_x = b_x.view(-1, 784).to(device)\n",
        "    z, b_x_hat = model(b_x) # forward propagation\n",
        "    loss = criterion(b_x_hat, b_x) # get cost\n",
        "\n",
        "    avg_cost += loss/total_batch_num\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() # backward propagation\n",
        "    optimizer.step() # update parameters\n",
        "  print('Epoch : {} / {}, cost: {}'.format(epoch+1, epochs, avg_cost))\n",
        "\n",
        "  # observe differences\n",
        "  if epoch % 5 ==0:\n",
        "    model.eval()\n",
        "    fig, ax = plt.subplots(1,2)\n",
        "    with torch.no_grad():\n",
        "      test_z, test_output = model(sample)\n",
        "    ax[0].set_title('x')\n",
        "    ax[1].set_title('x_hat')\n",
        "\n",
        "    ax[0].set_axis_off()\n",
        "    ax[1].set_axis_off()\n",
        "    ax[0].imshow(np.reshape(sample.detach().cpu(),(28,28)), cmap='gray')\n",
        "    ax[1].imshow(np.reshape(test_output.detach().cpu(),(28,28)), cmap='gray')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "oUqwJJ1T0SAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 결과 확인\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "test_samples = torch.zeros((10,28,28))\n",
        "for i in range(10):\n",
        "  test_samples[i] = test_dataset[i][0]\n",
        "test_samples = test_samples.view(-1, 784).to(device)\n",
        "z, test_output = model(test_samples)\n",
        "\n",
        "fig, ax = plt.subplots(2, 10, figsize=(12,3))\n",
        "ax[0][0].set_title('x')\n",
        "ax[1][0].set_title('x_hat')\n",
        "for i in range(10):\n",
        "  ax[0][i].set_axis_off()\n",
        "  ax[1][i].set_axis_off()\n",
        "  ax[0][i].imshow(np.reshape(test_samples[i].detach().cpu(), (28,28)), camp='gray')\n",
        "  ax[1][i].imshow(np.reshape(test_output[i].detach().cpu(), (28,28)), camp='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IMyU204G1WfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Denoising Auto-Encoder model"
      ],
      "metadata": {
        "id": "F64RKujs6c0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  avg_cost = 0\n",
        "  total_batch_num = len(train_dataloader)\n",
        "\n",
        "  for b_x, b_y in train_dataloader:\n",
        "    b_x = b_x.view(-1, 784).to(device)\n",
        "    noise = torch.randn(b_x.shape).to(device)\n",
        "    noisy_b_x = b_x + noise\n",
        "    \n",
        "    z, b_x_hat = model(noisy_b_x) # forward propagation\n",
        "    loss = criterion(b_x_hat, b_x) # get cost\n",
        "\n",
        "    avg_cost += loss/total_batch_num\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() # backward propagation\n",
        "    optimizer.step() # update parameters\n",
        "  print('Epoch : {} / {}, cost: {}'.format(epoch+1, epochs, avg_cost))\n",
        "\n",
        "  # observe differences\n",
        "  model.eval()\n",
        "  if epoch % 5 ==0:\n",
        "    fig, ax = plt.subplots(1,3)\n",
        "    with torch.no_grad():\n",
        "      noise = torch.randn(sample.shape).to(device)\n",
        "      noisy_sample = sample + noise\n",
        "      test_z, test_output = model(noisy_sample)\n",
        "    ax[0].set_title('x')\n",
        "    ax[1].set_title('x_noise')\n",
        "    ax[2].set_title('x_hat')\n",
        "\n",
        "    ax[0].set_axis_off()\n",
        "    ax[1].set_axis_off()\n",
        "    ax[2].set_axis_off()\n",
        "    ax[0].imshow(np.reshape(sample.detach().cpu(),(28,28)), cmap='gray')\n",
        "    ax[1].imshow(np.reshape(noisy_sample.detach().cpu(),(28,28)), cmap='gray')\n",
        "    ax[2].imshow(np.reshape(test_output.detach().cpu(),(28,28)), cmap='gray')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "i9XNZuoP3vA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 결과 확인\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "test_samples = torch.zeros((10,28,28))\n",
        "for i in range(10):\n",
        "  test_samples[i] = test_dataset[i][0]\n",
        "\n",
        "noise = torch.randn(test_samples.shape)\n",
        "noisy_test_samples = test_samples + noise\n",
        "\n",
        "noisy_test_samples = noisy_test_samples.view(-1, 784).to(device)\n",
        "\n",
        "z, test_output = model(noisy_test_samples)\n",
        "\n",
        "fig, ax = plt.subplots(3, 10, figsize=(12,4))\n",
        "\n",
        "ax[0][0].set_title('x')\n",
        "ax[1][0].set_title('x_noise')\n",
        "ax[2][0].set_title('x_hat')\n",
        "\n",
        "for i in range(10):\n",
        "  ax[0][i].set_axis_off()\n",
        "  ax[1][i].set_axis_off()\n",
        "  ax[2][i].set_axis_off()\n",
        "\n",
        "  ax[0][i].imshow(test_samples[i].detach().cpu(), camp='gray')\n",
        "  ax[1][i].imshow(np.reshape(noisy_test_samples[i].detach().cpu(), (28,28)), camp='gray')\n",
        "  ax[2][i].imshow(np.reshape(test_output[i].detach().cpu(), (28,28)), camp='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W-j0Lyed3vEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stacked AutoEncoder and Semi-Supervised Learning"
      ],
      "metadata": {
        "id": "m3L33Zn8-vLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Encoder1, self).__init__()\n",
        "    self.linear = nn.Linear(784, 256)\n",
        "    self.activation = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear(x)\n",
        "    x = self.activation(x)\n",
        "    return x\n",
        "\n",
        "class Decoder1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Decoder1, self).__init__()\n",
        "    self.linear = nn.Linear(256, 784)\n",
        "    self.activation = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear(x)\n",
        "    x = self.activation(x)\n",
        "    return x\n",
        "\n",
        "class AutoEncoder1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(AutoEncoder1, self).__init__()\n",
        "    self.encoder = Encoder1()\n",
        "    self.decoder = Decoder1()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    z = self.encoder(x)\n",
        "    x_hat = self.decoder(z)\n",
        "    return z, x_hat"
      ],
      "metadata": {
        "id": "AHkRP1qc-yOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Encoder2, self).__init__()\n",
        "    self.linear = nn.Linear(256, 64)\n",
        "    self.activation = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear(x)\n",
        "    x = self.activation(x)\n",
        "    return x\n",
        "\n",
        "class Decoder2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Decoder2, self).__init__()\n",
        "    self.linear = nn.Linear(64, 256)\n",
        "    self.activation = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear(x)\n",
        "    x = self.activation(x)\n",
        "    return x\n",
        "\n",
        "class AutoEncoder2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(AutoEncoder2, self).__init__()\n",
        "    self.encoder = Encoder2()\n",
        "    self.decoder = Decoder2()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    z = self.encoder(x)\n",
        "    x_hat = self.decoder(z)\n",
        "    return z, x_hat"
      ],
      "metadata": {
        "id": "8NSC0yUA_FL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder1 = AutoEncoder1().to(device).train()\n",
        "autoencoder2 = AutoEncoder2().to(device).train()"
      ],
      "metadata": {
        "id": "B1jd4P_X_FPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_1 = optim.Adam(autoencoder1.parameters(), lr=0.001) \n",
        "optimizer_2 = optim.Adam(autoencoder2.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "n52nAjBO_FTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "zPeNxPlw_FXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "\n",
        "autoencoder1.train()\n",
        "for epoch in range(epochs):\n",
        "  autoencoder1.train()\n",
        "  avg_cost = 0\n",
        "  total_batch_num = len(train_dataloader)\n",
        "\n",
        "  for b_x, b_y in train_dataloader:\n",
        "    b_x = b_x.view(-1, 784).to(device)\n",
        "    z, b_x_hat = autoencoder1(b_x) # forward propagation\n",
        "    loss = criterion(b_x_hat, b_x) # get cost\n",
        "\n",
        "    avg_cost += loss/total_batch_num\n",
        "    optimizer_1.zero_grad()\n",
        "    loss.backward() # backward propagation\n",
        "    optimizer_1.step() # update parameters\n",
        "  print('Epoch : {} / {}, cost: {}'.format(epoch+1, epochs, avg_cost))"
      ],
      "metadata": {
        "id": "AU6UsX9e_Faz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "\n",
        "autoencoder1.eval() # freeze first autoencoder\n",
        "autoencoder2.train()\n",
        "for epoch in range(epochs):\n",
        "  autoencoder2.train()\n",
        "  avg_cost = 0\n",
        "  total_batch_num = len(train_dataloader)\n",
        "\n",
        "  for b_x, b_y in train_dataloader:\n",
        "    b_x = b_x.view(-1, 784).to(device)\n",
        "    with torch.no_grad():\n",
        "      z1, b_x_hat = autoencoder1(b_x) # get latent representation from first encoder\n",
        "    z2, b_x_hat = autoencoder2(z1)\n",
        "    loss = criterion(b_x_hat, z1) # get cost\n",
        "\n",
        "    avg_cost += loss/total_batch_num\n",
        "    optimizer_2.zero_grad()\n",
        "    loss.backward() # backward propagation\n",
        "    optimizer_2.step() # update parameters\n",
        "  print('Epoch : {} / {}, cost: {}'.format(epoch+1, epochs, avg_cost))"
      ],
      "metadata": {
        "id": "muDO9CSsAKHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classifier, self).__init__()\n",
        "    self.linear = nn.Linear(64,32)\n",
        "    self.activation = nn.Sigmoid()\n",
        "    self.cls = nn.Linear(32,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear(x)\n",
        "    x = self.activation(x)\n",
        "\n",
        "    x = self.cls(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "fvtQ0x_XAKKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Classifier().to(device)"
      ],
      "metadata": {
        "id": "P09QhBOXAKNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cls_criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "5qSBrEtgAKRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(\n",
        "    [\n",
        "        {\"params\": autoencoder1.parameters(), \"lr\":0.001},\n",
        "        {\"params\": autoencoder2.parameters(), \"lr\":0.001},\n",
        "        {\"params\": classifier.parameters(), \"lr\":0.001},\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "madaM_B4AKTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Classifier 학습\n",
        "Fine-tuning autoencoder\n",
        "* Fine-tume: 미리 학습된 weight을 task에 맞게 학습하는 것\n",
        "'''\n",
        "autoencoder1.train() \n",
        "autoencoder2.train()\n",
        "classifier.train()\n",
        "total_batch_num = len(train_dataloader)\n",
        "epochs = 30\n",
        "for epoch in range(epochs):\n",
        "  avg_cost = 0\n",
        "\n",
        "  for b_x, b_y in train_dataloader:\n",
        "    b_x = b_x.view(-1, 784).to(device)\n",
        "    z1, b_x_hat = autoencoder1(b_x) # get latent representation from first encoder\n",
        "    z2, b_x_hat2 = autoencoder2(z1) # get latent representation from second encoder\n",
        "    logits = classifier(z2) # classification\n",
        "    loss = criterion(logits, b_y.to(device)) # get cost\n",
        "\n",
        "    avg_cost += loss/total_batch_num\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward() # backward propagation\n",
        "    \n",
        "    optimizer.step() # update parameters\n",
        "  print('Epoch : {} / {}, cost: {}'.format(epoch+1, epochs, avg_cost))"
      ],
      "metadata": {
        "id": "OUlpxSn0BzEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "classifier.eval()\n",
        "autoencoder1.eval()\n",
        "autoencoder2.eval()\n",
        "\n",
        "for b_x, b_y in test_dataloader:\n",
        "  b_x = b_x.view(-1, 784).to(device)\n",
        "  with torch.no_grad():\n",
        "    z1, b_x_hat = autoencoder1(b_x)\n",
        "    z2, b_x_hat2 = autoencoder2(z1)\n",
        "    logits = classifier(z2)\n",
        "\n",
        "  predicts = torch.argmax(logits, dim=1)\n",
        "\n",
        "  total += len(b_y)\n",
        "  correct += (predicts == b_y.to(device)).sum().item()\n",
        "\n",
        "print(f\"Accuracy of the network on test images: {100*correct/total} %\")"
      ],
      "metadata": {
        "id": "5lWfssnZCxQ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}